# test_performance.py

import time
import asyncio
from rag_engine import OptimizedPersonalAssistant
import config as config

class PerformanceTest:
    def __init__(self, model_name="llama3.2:3b"):
        self.model_name = model_name
        self.assistant = None
        self.results = {}
    
    def setup(self):
        """Initialize assistant"""
        print(f"[SETUP] Initializing {self.model_name}...")
        start_time = time.time()
        
        self.assistant = OptimizedPersonalAssistant(
            model_name=self.model_name,
            temperature=0.3,
            top_p=0.9,
            top_k=20,
            presence_penalty=1.2
        )
        
        setup_time = time.time() - start_time
        self.results['setup_time'] = setup_time
        print(f"[SETUP] Complete in {setup_time:.2f}s")
    
    def test_cold_start(self):
        """Test first query (cold start)"""
        print("[TEST] Cold start query...")
        start_time = time.time()
        
        response = self.assistant.query("Xin ch√†o! B·∫°n c√≥ th·ªÉ gi√∫p g√¨ cho t√¥i?")
        
        cold_start_time = time.time() - start_time
        self.results['cold_start'] = cold_start_time
        print(f"[RESULT] Cold start: {cold_start_time:.2f}s")
        print(f"[RESPONSE] {response[:100]}...")
    
    def test_warm_queries(self):
        """Test subsequent queries (warm)"""
        print("[TEST] Warm queries...")
        
        queries = [
            "T√¥i c·∫£m th·∫•y h√¥m nay r·∫•t t·ªët",
            "G·ª£i √Ω b·ªØa s√°ng healthy cho t√¥i",
            "L√†m th·∫ø n√†o ƒë·ªÉ tƒÉng nƒÉng su·∫•t l√†m vi·ªác?",
            "T·∫°o l·ªãch t·∫≠p gym cho ng∆∞·ªùi m·ªõi",
            "Ph√¢n t√≠ch t√¢m tr·∫°ng tu·∫ßn n√†y"
        ]
        
        warm_times = []
        
        for i, query in enumerate(queries):
            start_time = time.time()
            response = self.assistant.query(query)
            query_time = time.time() - start_time
            warm_times.append(query_time)
            
            print(f"[WARM {i+1}] {query_time:.2f}s - {query[:30]}...")
        
        avg_warm_time = sum(warm_times) / len(warm_times)
        self.results['warm_queries'] = warm_times
        self.results['avg_warm_time'] = avg_warm_time
        print(f"[RESULT] Average warm time: {avg_warm_time:.2f}s")
    
    def test_cache_hit(self):
        """Test cache performance"""
        print("[TEST] Cache hit performance...")
        
        query = "T√¥i c·∫£m th·∫•y h√¥m nay r·∫•t t·ªët"
        
        # First query (cache miss)
        start_time = time.time()
        response1 = self.assistant.query(query)
        miss_time = time.time() - start_time
        
        # Second query (cache hit)
        start_time = time.time()
        response2 = self.assistant.query(query)
        hit_time = time.time() - start_time
        
        speedup = miss_time / hit_time if hit_time > 0 else float('inf')
        
        self.results['cache_miss'] = miss_time
        self.results['cache_hit'] = hit_time
        self.results['cache_speedup'] = speedup
        
        print(f"[RESULT] Cache miss: {miss_time:.2f}s")
        print(f"[RESULT] Cache hit: {hit_time:.2f}s")
        print(f"[RESULT] Speedup: {speedup:.1f}x")
    
    def test_diary_processing(self):
        """Test diary entry processing"""
        print("[TEST] Diary processing...")
        
        diary_content = """
        H√¥m nay t√¥i d·∫≠y l√∫c 6h30, c·∫£m th·∫•y kh√° t∆∞∆°i t·ªânh. 
        ƒÇn s√°ng ph·ªü b√≤, u·ªëng c√† ph√™ ƒëen. 
        L√†m vi·ªác t·ª´ 8h ƒë·∫øn 17h, c√≥ h·ªçp team l√∫c 14h.
        T·∫≠p gym 45 ph√∫t, ch·∫°y b·ªô 3km.
        ƒÇn t·ªëi v·ªõi gia ƒë√¨nh, xem phim Netflix.
        ƒêi ng·ªß l√∫c 22h30, c·∫£m th·∫•y h√†i l√≤ng v·ªõi ng√†y h√¥m nay.
        """
        
        start_time = time.time()
        result = self.assistant.add_diary_entry(diary_content, "2024-08-04")
        processing_time = time.time() - start_time
        
        self.results['diary_processing'] = processing_time
        print(f"[RESULT] Diary processing: {processing_time:.2f}s")
        print(f"[RESPONSE] {result}")
    
    def test_memory_usage(self):
        """Test memory usage (if psutil available)"""
        try:
            import psutil
            import os
            
            process = psutil.Process(os.getpid())
            memory_mb = process.memory_info().rss / 1024 / 1024
            
            self.results['memory_usage_mb'] = memory_mb
            print(f"[RESULT] Memory usage: {memory_mb:.1f} MB")
            
        except ImportError:
            print("[SKIP] psutil not available, skipping memory test")
    
    def run_all_tests(self):
        """Run complete test suite"""
        print("="*60)
        print(f"PERFORMANCE TEST SUITE - {self.model_name}")
        print("="*60)
        
        self.setup()
        self.test_cold_start()
        self.test_warm_queries()
        self.test_cache_hit()
        self.test_diary_processing()
        self.test_memory_usage()
        
        self.print_summary()
    
    def print_summary(self):
        """Print test summary"""
        print("\n" + "="*60)
        print("PERFORMANCE SUMMARY")
        print("="*60)
        
        print(f"Model: {self.model_name}")
        print(f"Setup time: {self.results.get('setup_time', 0):.2f}s")
        print(f"Cold start: {self.results.get('cold_start', 0):.2f}s")
        print(f"Average warm query: {self.results.get('avg_warm_time', 0):.2f}s")
        print(f"Cache speedup: {self.results.get('cache_speedup', 0):.1f}x")
        print(f"Diary processing: {self.results.get('diary_processing', 0):.2f}s")
        
        if 'memory_usage_mb' in self.results:
            print(f"Memory usage: {self.results['memory_usage_mb']:.1f} MB")
        
        # Performance rating
        avg_time = self.results.get('avg_warm_time', 999)
        if avg_time < 2.0:
            rating = "üöÄ Excellent"
        elif avg_time < 5.0:
            rating = "‚úÖ Good"
        elif avg_time < 10.0:
            rating = "‚ö†Ô∏è Acceptable"
        else:
            rating = "‚ùå Needs optimization"
        
        print(f"Overall rating: {rating}")
        print("="*60)

def compare_models():
    """Compare multiple models"""
    models = ["llama3.2:3b", "gemma2:2b"]  # Add more models as needed
    
    for model in models:
        try:
            test = PerformanceTest(model)
            test.run_all_tests()
            print("\n" + "-"*60 + "\n")
        except Exception as e:
            print(f"[ERROR] Failed to test {model}: {e}")

if __name__ == "__main__":
    # Test single model
    test = PerformanceTest("llama3.2:3b")
    test.run_all_tests()
    
    # Uncomment to compare multiple models
    # compare_models()